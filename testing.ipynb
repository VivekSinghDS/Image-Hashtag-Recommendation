{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7862ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1e59160",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (160, 160, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = MobileNetV2(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "neural_network = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "])\n",
    "def prepare_image(img_path, height = 160, width = 160, where = 'local'):\n",
    "    \n",
    "    img = tf.io.read_file(img_path)\n",
    "    \n",
    "    img = tf.image.decode_image(img)\n",
    "    \n",
    "    img = tf.cast(img, tf.float32)\n",
    "    \n",
    "    img = (img/127.5)-1\n",
    "    \n",
    "    img = tf.image.resize(img, (height, width))\n",
    "    \n",
    "    \n",
    "    if img.shape!=(160, 160, 3):\n",
    "        img = tf.concat([img, img, img], axis = 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "def extract_features(image, neural_network):\n",
    "    image_np = image.numpy()\n",
    "    image_np = np.expand_dims(image_np, axis = 0)\n",
    "    deep_features = neural_network.predict(image_np)[0]\n",
    "    return deep_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55c90e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_local_name</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>deep_features</th>\n",
       "      <th>id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>471</td>\n",
       "      <td>cc6687dc-e2e5-417b-9372-faa5527ed25d.jpg</td>\n",
       "      <td>['#monsieurbebelife', '#Ivorianbaby', '#monsie...</td>\n",
       "      <td>[0.2264766, 0.042613965, 0.7752272, 0.3973327,...</td>\n",
       "      <td>471</td>\n",
       "      <td>[-0.15784144401550293, 0.5163793563842773, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>463</td>\n",
       "      <td>bf96dc78-d4f8-4f35-a2ec-9605803a37c7.jpg</td>\n",
       "      <td>['#cats', '#futuremaman', '#birman', '#maman',...</td>\n",
       "      <td>[0.0, 1.7325919, 0.12030285, 0.32206786, 0.316...</td>\n",
       "      <td>463</td>\n",
       "      <td>[-0.057306136935949326, -0.2672276794910431, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833</td>\n",
       "      <td>3b019eed-2e12-4e9a-a49c-ce131257e71e.jpg</td>\n",
       "      <td>['#pet', '#godoxlighting', '#portraitphotograp...</td>\n",
       "      <td>[0.0, 0.0, 0.029408284, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>833</td>\n",
       "      <td>[-0.3648046553134918, -0.5840925574302673, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148</td>\n",
       "      <td>08c86967-0dec-45d0-947e-8919b342714b.jpg</td>\n",
       "      <td>['#nature', '#CzechGirl', '#BeautyOfNature', '...</td>\n",
       "      <td>[0.0, 0.47515857, 0.054196358, 0.98798513, 0.4...</td>\n",
       "      <td>148</td>\n",
       "      <td>[-0.11143600195646286, -0.14699919521808624, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540</td>\n",
       "      <td>415c35ed-6177-4be1-b6d1-59e689acb1e9.jpg</td>\n",
       "      <td>['#td', '#gqpatrol', '#gq', '#kettle', '#patrol']</td>\n",
       "      <td>[0.0, 0.0, 1.2779106, 0.0, 0.0, 2.1347184, 1.9...</td>\n",
       "      <td>540</td>\n",
       "      <td>[0.0040685334242880344, -0.0004095354815945029...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          image_local_name  \\\n",
       "0         471  cc6687dc-e2e5-417b-9372-faa5527ed25d.jpg   \n",
       "1         463  bf96dc78-d4f8-4f35-a2ec-9605803a37c7.jpg   \n",
       "2         833  3b019eed-2e12-4e9a-a49c-ce131257e71e.jpg   \n",
       "3         148  08c86967-0dec-45d0-947e-8919b342714b.jpg   \n",
       "4         540  415c35ed-6177-4be1-b6d1-59e689acb1e9.jpg   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  ['#monsieurbebelife', '#Ivorianbaby', '#monsie...   \n",
       "1  ['#cats', '#futuremaman', '#birman', '#maman',...   \n",
       "2  ['#pet', '#godoxlighting', '#portraitphotograp...   \n",
       "3  ['#nature', '#CzechGirl', '#BeautyOfNature', '...   \n",
       "4  ['#td', '#gqpatrol', '#gq', '#kettle', '#patrol']   \n",
       "\n",
       "                                       deep_features   id  \\\n",
       "0  [0.2264766, 0.042613965, 0.7752272, 0.3973327,...  471   \n",
       "1  [0.0, 1.7325919, 0.12030285, 0.32206786, 0.316...  463   \n",
       "2  [0.0, 0.0, 0.029408284, 0.0, 0.0, 0.0, 0.0, 0....  833   \n",
       "3  [0.0, 0.47515857, 0.054196358, 0.98798513, 0.4...  148   \n",
       "4  [0.0, 0.0, 1.2779106, 0.0, 0.0, 2.1347184, 1.9...  540   \n",
       "\n",
       "                                            features  \n",
       "0  [-0.15784144401550293, 0.5163793563842773, -0....  \n",
       "1  [-0.057306136935949326, -0.2672276794910431, -...  \n",
       "2  [-0.3648046553134918, -0.5840925574302673, 0.5...  \n",
       "3  [-0.11143600195646286, -0.14699919521808624, 0...  \n",
       "4  [0.0040685334242880344, -0.0004095354815945029...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "recommender_df = pd.read_csv('iter1_recommender.csv')\n",
    "pics = pd.read_csv('pics.csv')\n",
    "recommender_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ff25043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbor_vectors(image_path, k=5, recommender_df=recommender_df):\n",
    "    \"\"\"Find image features (user vectors) for similar images.\"\"\"\n",
    "    prep_image = prepare_image(image_path, where='local')\n",
    "    pics = extract_features(prep_image, neural_network)\n",
    "    rdf = recommender_df.copy()\n",
    "    rdf['dist'] = rdf['deep_features'].apply(lambda x: cosine(x, pics))\n",
    "    rdf = rdf.sort_values(by='dist')\n",
    "    return rdf.head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2eebf875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hashtags(image_path):\n",
    "    fnv = find_neighbor_vectors(image_path, k=5, recommender_df=recommender_df)\n",
    "    # Find the average of the 5 user features found based on cosine similarity.\n",
    "    features = []\n",
    "    for item in fnv.features.values:\n",
    "        features.append(item)\n",
    "\n",
    "    avg_features = np.mean(np.asarray(features), axis=0)\n",
    "    \n",
    "    # Add new column to the hashtag features which will be the dot product with the average image(user) features\n",
    "    hashtag_features['dot_product'] = hashtag_features['features'].apply(lambda x: np.asarray(x).dot(avg_features))\n",
    "\n",
    "    # Find the 10 hashtags with the highest feature dot products\n",
    "    final_recs = hashtag_features.sort_values(by='dot_product', ascending=False).head(10)\n",
    "    # Look up hashtags by their numeric IDs\n",
    "    output = []\n",
    "    for hashtag_id in final_recs.id.values:\n",
    "        output.append(hashtags_df.iloc[hashtag_id]['hashtag'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3475594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(test_image):\n",
    "    img = mpimg.imread(f'test/{test_image}.jpeg')\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.title(f'File Name: {test_image.upper()}', fontsize=32)        \n",
    "    plt.imshow(img)\n",
    "    \n",
    "    recommended_hashtags = generate_hashtags(f'test/{test_image}.jpeg')\n",
    "    print(', '.join(recommended_hashtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b66e1be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: array([0.2264766 , 0.04261396, 0.7752272 , ..., 0.52041703, 0.        ,\n       0.07019943])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_c/g6y8797n7pj_l0y8d0v4j8ph0000gn/T/ipykernel_47631/3410326798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommender_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deep_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrecommender_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deep_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommender_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deep_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0m_raise_malformed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mnode_or_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_or_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raise_malformed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'malformed node or string: {node!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: array([0.2264766 , 0.04261396, 0.7752272 , ..., 0.52041703, 0.        ,\n       0.07019943])"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import numpy\n",
    "for i in range(len(recommender_df['deep_features'])):\n",
    "    print(i)\n",
    "    recommender_df['deep_features'][i] = numpy.array(literal_eval(recommender_df['deep_features'][i]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "380fdaf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/vivek/DSwork/image_hashtag_recommendation/img_h_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3444\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/var/folders/_c/g6y8797n7pj_l0y8d0v4j8ph0000gn/T/ipykernel_47631/2261484493.py\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    pics['deep_features'][i] = numpy.array(literal_eval(pics['deep_features'][i]))\n",
      "  File \u001b[1;32m\"/Users/vivek/opt/anaconda3/lib/python3.8/ast.py\"\u001b[0m, line \u001b[1;32m59\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/vivek/opt/anaconda3/lib/python3.8/ast.py\"\u001b[0;36m, line \u001b[0;32m47\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [1.012492   0.28948903 0.         ... 2.1862402  0.         0.        ]\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(pics['deep_features'])):\n",
    "    pics['deep_features'][i] = numpy.array(literal_eval(pics['deep_features'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee281ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(numpy.array(literal_eval(recommender_df['deep_features'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4af5b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('[0.2264766  0.04261396 0.7752272  ... 0.52041703 0.         0.07019943]',\n",
       "      dtype='<U71')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(recommender_df['deep_features'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92ba7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = recommender_df['deep_features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df8d0646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.2264766  0.04261396 0.7752272  ... 0.52041703 0.         0.07019943]'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3875c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_h_env",
   "language": "python",
   "name": "img_h_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
